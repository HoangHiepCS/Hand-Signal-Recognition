# Hand-Signal-Recognition
A real-time hand signal recognition model using Python and user camera input, aimed at automotive applications to enable gesture-based vehicle control, especially beneficial for individuals who are mute.
Used Tensorflow/Keras to build and train neural network models, specifically LSTM network for sequential data classification, and Scikit-Learn to handle data and evaluate models. 
Used OpenCV to access the webcam and display video frames with annotations and key landmarks, Mediapipe to detect and track landmarks. 
Successfully recognized gestures: Like (1 hand), Super Like (both hands), Dislike (1 hand), Super Dislike (both hands), Congratulate (1 hand), and Super Congratulate (both hands), with nearly 100% accuracy.
